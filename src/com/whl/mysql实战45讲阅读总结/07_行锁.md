### 行锁

我们知道提高并发效率可以通过细粒度锁实现，这里的行锁就是相比起表锁更加细粒度的锁。在mysql中，行锁由各个引擎层自己实现，但也并不是所有引擎都支持行锁，例如MyISAM就不支持行锁，对于使用这种引擎的表，任意时刻只能允许一个更新操作在执行，这也是InnoDB取代MyISAM的原因之一。

行锁，顾名思义就是当事务更新某行时，会对行加锁，其他事务可以更新其他未加锁的行，但更新加锁的行时需要等待获取行锁。



### 两阶段锁协议

![img](https://static001.geekbang.org/resource/image/51/10/51f501f718e420244b0a2ec2ce858710.jpg)

如图所示，事务A在执行完两条update语句后，会继续持有id=1、id=2两条记录的行锁，直到commit之后才会释放；事务B需要等待事务A commit之后，才能够获取到行锁，执行update语句。这就是二阶段锁协议。

明确了二阶段锁协议之后，我们可以依此优化事务的执行效率。例如，电影院在线交易的业务中，事务涉及了以下操作：

1. 从顾客账户中扣除余额
2. 电影院账户余额增加顾客扣除的金额

3. 记录一条交易日志

如果是根据1、2、3的顺序执行，假如A、B同时购票，在A、B都同时执行到“增加电影院账户余额”时，A先获取到行锁，此时B必须等待A执行完2、3的操作，提交事务释放锁后才能继续执行。

根据二阶段锁协议，我们只需要把最有可能造成互斥的操作尽量往后放即可提高并发量。例如：我们可以按照3、1、2的顺序执行。这样，假如A、B同时购票，记录交易日志，扣除账户余额的操作就不会互斥，而是直到增加电影院账户余额时才有可能互斥。这就最大程度地减少了事务之间的锁等待，提高了并发量。



### 死锁以及死锁检测

行锁是比表锁更细粒度的锁，而锁的粒度越细，则越有可能造成死锁。例如下图中，事务A获取到了id=1记录的行锁，事务B获取到了id=2记录的行锁；此时事务A需要获取id=2的锁，事务B需要获取id=1的锁，事务A与事务B之间互相无限等待对方释放锁，就造成了死锁：

![img](https://static001.geekbang.org/resource/image/4d/52/4d0eeec7b136371b79248a0aed005a52.jpg)

解决死锁的策略有两种：

1. 设置超时，当事务等待获取锁到达超时时限，则释放锁，且事务回滚。这个超时时间可以通过设置参数 innodb_lock_wait_timeout 实现，innodb默认指定为50s。
2. 设置死锁检测，当检测到死锁后，主动回滚死锁链条中的某个事务，使得其他事务得以继续执行。死锁检测可以通过语句 set innodb_deadlock_detect = on 开启。

mysql中，解决死锁的主要手段还是通过策略2，因为策略1的话，如果数值太大，发生死锁时等待得未免太久；如果数值太小，又很可能会误伤那些等待获取锁的事务。

但是策略2也并非完美无缺，死锁检测无非就是判断一个新开启的线程会不会与它所依赖的线程构成循环等待条件。

需要注意的是，死锁检测只会检测存在依赖关系的线程，例如B在等A，D在等C，新来一个E需要等C，死锁检测就会判断E会不会与D，C构成死锁，与A、B无关。还有就是，一致性读不会加锁，因此不需要死锁检测。

假设有1000个并发线程要更新同一行，那么死锁检测就是100w的量级的，如果最终检测没有构成死锁，那么就会浪费掉大量的资源在检测上。

假设一个电影院开启线上电影票低价限时秒杀活动，如果并发的线程很多，并且开启了死锁检测，那么就很可能看见一个场景，CPU消耗将近100%，但数据库每秒才执行不到100个事务，这就是因为CPU全消耗在死锁检测上了。针对这个问题，解决思路有三种：

1. 如果确保业务不会出现死锁，可以临时关闭死锁检测。
2. 控制mysql的并发度（有点类似Java并发编程中的限流器），每个时刻只允许最多10个线程执行更新操作，此时死锁检测成本很低，就不会出现上述问题。
3. 既然互斥发生在 “电影院账户余额增加顾客扣除的金额” 这个流程，我们可以将一个电影院账户余额记录分散在多条记录上，比如分散为10个记录。这样，事务执行到 “电影院账户余额增加顾客扣除的金额” 时，随机选取10条记录中的1个进行增加，这样冲突的概率就减小为原先的1/10。通过减少互斥出现可能性，也间接就减少了死锁检测的CPU消耗。



### 问题汇总

##### 如果要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：1，直接执行 delete from T limit 10000；2，在一个连接中循环执行 20 次 delete from T limit 500；3，在 20 个连接中同时执行 delete from T limit 500；哪一种方法更优？

第一种，单个语句占用的时间较长，会导致其他客户端等待资源时间较长。

第三种，因为删除操作会加锁，并且锁的释放是在事务提交后才释放，这就人为地增大了互斥的可能。

相比之下，第二种更好。