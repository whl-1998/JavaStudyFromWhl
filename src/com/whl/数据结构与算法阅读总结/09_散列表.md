### 一、散列表概念

散列表，也称为Hash表，底层基于数组实现，在某些情况下数组也可以用作一个简单的散列表。

假设有89名选手参加运动会，且每个选手的编号依次是1 - 89，如果需要实现：通过编号快速找到对应选手的信息，该如何实现。

最简单的思路就是将89个选手依次放在数组中，编号为1的选手就放在数组 index=1 的下标，以此类推。当我们需要查询编号为 x 的选手时，只需要将数组中下标为 index=x 的元素取出即可，时间复杂度为O(1)。而这个思路其实就已经用到了散列的思想，这个例子中，参赛编号与数组下标形成映射，因此基于数组支持快速随机访问的特性，我们能够很快地获取到编号对应的选手信息。

如果参赛编号需要设置得更加复杂一些，加上年级、班级等更详细的信息。例如021167，前两位表示年级，中间两位表示班级，最后两位依旧是1 - 89，上述思路就不可行了，我们不可能将开辟一个 1 * 10^7 大小的数组。此时，我们可以将这个6位的编号通过一个散列函数取最后两位作为下标存储到数组。伪代码如下所示：

```java
Athletes aths[] = new Athletes[89];//开辟长度为89的数组
int index = hash(athObj.number) = 67;//通过散列函数处理选手编号
aths[index] = athObj;//在index位置处放置选手对象
```

这就是典型的散列思想，其中我们将选手的编号称之为key，对应key的选手对象称之为value，而将选手编号转换为数组下标的函数称之为散列函数，通过散列函数得到的值称作散列值。

通过上述例子我们能够得知，散列表的核心思想就是利用数组快速随机访问的特性，实现通过key值快速检索到对应value的操作。



### 二、散列函数

散列函数，一般是用于处理key，使得key能够转换为有效的数组下标。例如上述例子中需要将6位编号转换为2位的数组下标，我们就可以将散列函数如下定义：

```java
int hash(String key) {
	String lastTwoChars = key.substr(key.length() - 2, key.length());
    return Integer.valueOf(lastTwoChars);
}
```

上述散列函数比较简单，但是大多数情况下散列函数的要求是很苛刻的：

1. 散列函数得到的散列值必须是非负整数
2. 如果key1 == key2，那么hash(key1) == hash(key2)
3. 如果key1 != key2，那么hash(key1) != hash(key2)

但在现实世界中，一个完美的散列函数是不存在的。这就意味着我们无法避免上述的第三中情况，也就是所谓的**散列冲突**情况。此时，就有两种针对散列冲突提出的解决方案：

1. **开放寻址法：**

   开放寻址发要求如果插入操作时出现散列冲突，就从散列表头部开始遍历寻找一个空的位置放入value，这种探测方式也称为**线程探测**。具体流程如下图所示：

   ![img](https://static001.geekbang.org/resource/image/5c/d5/5c31a3127cbc00f0c63409bbe1fbd0d5.jpg)

   上图中，x经过hash算法之后得到散列值为7的下标位置，但是发现index==7的位置上已经有数据了，于是从头开始遍历，寻找到index==2的位置为空，再进行插入。

   相对应的，检索操作也需要作一定的变更。例如检索某个元素y时，先查看index == hash(y)的位置上的元素是否与检索元素y的key相同，如果相同说明成功找到。如果不相同则需要从头开始遍历，直到成功检索到目标元素位置。

   可以看出，开放寻址法其实存在着很大的问题。如果散列表几乎已满的状态下，发生hash冲突的可能性就越来越大，线性探测的时间就越来越久，在极端情况下，需要遍历整个散列表。因此在工业级散列表的实现中，采用的几乎都是拉链法来解决hash冲突。

   采用开放寻址法解决hash冲突，那么散列表中的数据都存储在数组中，这样就可以有效利用CPU缓存加快查询的速度。而且，这种方法实现的散列表序列化操作也更加简单。但缺点在于删除数据比较麻烦，需要特殊标记已经删除的数据。而且相比起拉链法，hash冲突的可能性也更高，因此使用开放寻址法解决冲突的散列表装载因子的上限不能太大，这个特点也带来了更加消耗内存空间的缺点。

   因此，当数据量比较小，且装载因子小的时候适合使用开放寻址法。这也是为什么Java中的ThreadLocalMap使用的开放寻址法解决hash冲突的原因。

2. **拉链法：**

   当插入的时候，如果遇到hash冲突的情况，则在对应的桶中插入一个链表结点。如下图所示：![img](https://static001.geekbang.org/resource/image/a4/7f/a4b77d593e4cb76acb2b0689294ec17f.jpg)

   当查找、删除一个元素时，先通过散列函数计算出对应的桶位置，然后执行遍历链表的查找或删除操作即可。

   链表法相比起开放寻址法，对装载因子的容忍度更高。开放寻址法只能适用于装载因子小于1的情况，并且接近1时就很可能带来大量的hash冲突。而对于拉链法来说，只要散列函数的分布足够均匀，即便是装载因子变成10，也仅仅是所有桶链表长度都各自增长了一点而已，虽然查询效率有所下降，但是相比起开放寻址法的顺序遍历还是要快很多。

   但链表法的缺点在于它的内存消耗。因为每个结点都需要存储指针，因此对于比较小的的对象存储是比较消耗内存的。而且，由于链表中各个结点的内存地址是零散分布的，因此也不支持CPU缓存。

由此可见，散列表的查询效率并不能笼统地认为是O(1)，而是要综合散列函数，装载因子，散列冲突来考量。若散列函数设计得不好，或装载因子过高，都可能导致散列冲突发生的概率升高，从而导致查询效率下降。

并且在极端情况下，恶意攻击者还可能故意制造哈希碰撞。若我们使用的是基于拉链法解决冲突的散列表，那么散列表就会退化为链表，查询时间由O(1)直接退化为O(n)。此时如果散列表中有10w个数据，那么退化后的散列表查询效率就下降了10w倍，这样就有可能因为查询操作大量消耗CPU或线程资源，从而导致系统无法响应其他请求，以此实现拒绝服务攻击DOS的目的。

那么如何设计一个散列函数，使其能够具备一定抵抗哈希碰撞攻击的能力呢？

首先，散列函数的实现不能过于复杂，过于复杂的散列函数会消耗很多的计算时间，间接影响了散列表的性能。

其次，散列函数生成的值要尽可能随机且均匀分布，这样才能最小化散列冲突的可能。



### 装载因子过大怎么办

装载因子越大，说明散列表中元素越多，空闲的位置越少，散列冲突的概率越大。不仅插入数据时要多次寻址或使链表变长，查找的过程也受到了一定的影响。

解决这个问题的思路和动态数组差不多，就是采用“动态扩容”的思想。针对散列表，当装载因子过大的时候，可以对散列表进行动态扩容，申请一个更大的散列表，将数据搬迁到新的散列表中。假设每次扩容我们都申请一个原散列表大小2倍的新表，那么新散列表的装载因子就变为了之前的一半。

但是散列表相比起数组，扩容的操作要复杂很多。因为散列表的大小变了，因此数据存储的位置也会有相应的变化，因此需要通过散列函数重新计算每个数据的存储位置。

![img](https://static001.geekbang.org/resource/image/67/43/67d12e07a7d673a9c1d14354ad029443.jpg)

例如上图中，value = 21 这个结点在扩容前存储位置是0，扩容后则变为存储在位置7了。

由此看来，插入一个数据在最优情况下，不需要扩容，时间复杂度为O(1)；在最坏情况下，散列表由于装载因子过大启动扩容，为此我们需要重新申请内存空间，重新计算哈希位置，并且搬迁数据，因此时间复杂度为O(n)。



### 如何避免低效的扩容

大部分情况下，动态扩容的散列表插入数据时都比较快，但是在特殊情况下，由于装载因子到达阈值，需要先执行扩容操作再插入数据，此时这个插入操作就会变得相当慢。例如，一个散列表大小为1Gb，如果要扩容为原两倍，那么就要对1Gb的数据重新计算哈希值，然后从原表搬迁到新表中，这是一个相当耗时的操作。

为了解决扩容耗时过多的问题，我们可以将扩容操作穿插在插入操作的过程中分批完成。当装载因子到达阈值时，只申请新的空间，但并不执行数据搬迁动作。当有新数据插入时，将新数据插入到新的散列表中，并且从旧散列表中拿出一个数据放到新散列表中。每当插入一次新数据，就搬迁一个老数据。经过多次插入操作之后，整个数据搬迁操作就逐渐完成了。没有集中的一次性数据搬迁操作，插入也就变得很快了，具体流程如下图所示：

![img](https://static001.geekbang.org/resource/image/6d/cb/6d6736f986ec4b75dabc5472965fb9cb.jpg)

那么对于查询操作，为了兼容新、旧散列表中的数据，我们先从新散列表中检索，如果没有找到再去旧散列表中检索。通过这种均摊的方法，将一次性扩容的代价均摊到了多次插入操作中，避免了一次性扩容耗时过多的情况。





